{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "\n",
    "highlight_author_lastname = 'Girardi-Schappo'\n",
    "\n",
    "publist = {\n",
    "    \"file\": \"D:/Dropbox/p/documentos/curriculum_vitae/template03_overleaf_em_uso/meus_artigos.bib\",\n",
    "    \"mastersthesis\": {\n",
    "        \"venuekey\": \"school\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"phdthesis\": {\n",
    "        \"venuekey\": \"school\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"incollection\": {\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"inproceedings\": {\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"book\": {\n",
    "        \"venuekey\": \"address\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"article\":{\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "\n",
    "def clean_bibstring(text):\n",
    "    return text.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED Girardi2010: \" Um modelo concreto para o estudo da estabilidade nuclear no  ... \"\n",
      "SUCESSFULLY PARSED Girardi2013Posit: \" A random walk approach to the diffusion of positrons in gase ... \"\n",
      "SUCESSFULLY PARSED Girardi2013map: \" A brief history of excitable map-based neurons and neural ne ... \"\n",
      "SUCESSFULLY PARSED Girardi2013aval: \" Critical avalanches and subsampling in map-based neural netw ... \"\n",
      "SUCESSFULLY PARSED Girardi2016dyn: \" Information processing occurs via critical avalanches in a m ... \"\n",
      "SUCESSFULLY PARSED Girardi2016: \" {G}riffiths phase and long-range correlations in a biologica ... \"\n",
      "SUCESSFULLY PARSED Girardi2017: \" Phase diagrams and dynamics of a computationally efficient m ... \"\n",
      "SUCESSFULLY PARSED Girardi2018: \" Measuring neuronal avalanches in disordered systems with abs ... \"\n",
      "SUCESSFULLY PARSED Girardi2019: \" Comment on ``{C}onvergence towards asymptotic state in 1-{D} ... \"\n",
      "SUCESSFULLY PARSED Lima2020Grang: \" {G}ranger causality in the frequency domain: derivation and  ... \"\n",
      "SUCESSFULLY PARSED GirardiPLR2020: \" Hints from statistical physics and graph theory to build syn ... \"\n",
      "SUCESSFULLY PARSED Girardi2020bal: \" Synaptic balance due to homeostatically self-organized quasi ... \"\n",
      "SUCESSFULLY PARSED Girardi2021theory: \" A unified theory of E/I synaptic balance, quasicritical neur ... \"\n",
      "SUCESSFULLY PARSED Girardi2021aval: \" Brain criticality beyond avalanches: open problems and how t ... \"\n",
      "SUCESSFULLY PARSED Carvalho2021: \" Subsampled Directed-Percolation Models Explain Scaling Relat ... \"\n",
      "SUCESSFULLY PARSED Girardi2021Epil: \" Altered communication dynamics reflect cognitive deficits in ... \"\n",
      "SUCESSFULLY PARSED Shimoura2021Conn: \" Building a model of the brain: from detailed connectivity ma ... \"\n",
      "SUCESSFULLY PARSED Menesse2022: \" Homeostatic Criticality in Neuronal Networks  \"\n",
      "SUCESSFULLY PARSED Trinh2022hMC: \" Adaptive spike threshold dynamics associated with sparse spi ... \"\n",
      "SUCESSFULLY PARSED Rhamidda2024Sync: \" Optimal input reverberation and homeostatic self-organizatio ... \"\n",
      "SUCESSFULLY PARSED Xu2023CogMap: \" Shortcutting from self-motion signals: quantifying trajector ... \"\n",
      "SUCESSFULLY PARSED Xu2023.02.24.529984: \" Shortcutting from self-motion signals: quantifying trajector ... \"\n",
      "SUCESSFULLY PARSED JacquesFsc2: \" [Física]2  \"\n",
      "SUCESSFULLY PARSED Girardi2021Pseudo: \" Um plano para arredondar a Terra  \"\n",
      "SUCESSFULLY PARSED Girardi2012Astropos: \" A Simple Monte Carlo Approach to the Diffusion of Positrons  ... \"\n",
      "SUCESSFULLY PARSED girardiMC2021CNS: \" A minimal integrate-and-fire model for mossy cells  \"\n",
      "SUCESSFULLY PARSED girardiCNS: \" Signal propagation and neuronal avalanches analysis in netwo ... \"\n",
      "SUCESSFULLY PARSED girardiLogCNS2014: \" A map-based logistic neuron model: an efficient way to obtai ... \"\n",
      "SUCESSFULLY PARSED girardiSyncCNS2014: \" Neural frequency distributions may generate a new phase tran ... \"\n",
      "SUCESSFULLY PARSED girardiV1CNS2014: \" Optimal activity, avalanches and criticality in a model of t ... \"\n",
      "SUCESSFULLY PARSED Kinouchi2019Bern: \" How to self-organize a neuronal network towards the balanced ... \"\n",
      "SUCESSFULLY PARSED Girardi2019Bern: \" Power-law avalanches and all the synchronicity states emergi ... \"\n",
      "SUCESSFULLY PARSED Girardi2023Bern: \" Coding properties of networks with firing threshold adaptati ... \"\n",
      "SUCESSFULLY PARSED Girardi2019CNS: \" A map-based model for the membrane potential of healthy and  ... \"\n",
      "SUCESSFULLY PARSED girardiMestrado: \" Sincronização, transições de fase, criticalidade e subamostr ... \"\n",
      "SUCESSFULLY PARSED girardiDoutorado: \" Transições de fase em modelos do cérebro: uma abordagem comp ... \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = bibtex.Parser()\n",
    "bibdata = parser.parse_file(publist[\"file\"])\n",
    "pubtype_default = 'paper'\n",
    "\n",
    "#loop through the individual references in a given bibtex file\n",
    "for bib_id in bibdata.entries:\n",
    "    #reset default date\n",
    "    pub_year          = \"1900\"\n",
    "    pub_month_default = \"01\"\n",
    "    pub_day           = \"01\"\n",
    "    \n",
    "    b = bibdata.entries[bib_id].fields\n",
    "    \n",
    "    try:\n",
    "        pub_year = f'{b[\"year\"]}'\n",
    "        pub_month = f'{b[\"month\"]}' if 'month' in b.keys() else pub_month_default\n",
    "        pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "        pub_type = pubtype_default\n",
    "        if 'pubtype' in b:\n",
    "            pub_type = b['pubtype']\n",
    "        \n",
    "        #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "        clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")\n",
    "\n",
    "        #url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "        url_slug = re.sub(\"[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "        url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "        md_filename   = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "        html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "        #Build Citation from text\n",
    "        citation = \"\"\n",
    "\n",
    "        #citation authors - todo - add highlighting for primary author?\n",
    "        for k,author in enumerate(bibdata.entries[bib_id].persons[\"author\"]):\n",
    "            author_name = clean_bibstring(author.first_names[0]+\" \"+author.last_names[0])\n",
    "            if highlight_author_lastname == clean_bibstring(author.last_names[0]):\n",
    "                author_name = '<u>' + author_name + '</u>'\n",
    "            citation = citation+\" \"+author_name\n",
    "            if k<len(bibdata.entries[bib_id].persons[\"author\"]):\n",
    "                citation += ', '\n",
    "\n",
    "        # citation year\n",
    "        citation += ' ('+ pub_year +'):'\n",
    "\n",
    "        #citation title\n",
    "        citation = citation + \"<i>\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".</i>\"\n",
    "\n",
    "        #add venue logic depending on citation type\n",
    "        pubsource = bibdata.entries[bib_id].type.lower()\n",
    "        #if bibdata.entries[bib_id].type.lower() == 'article':\n",
    "        venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "        if bibdata.entries[bib_id].type.lower() in ['book','incollection','inproceedings']:\n",
    "            if 'publisher' in b.keys():\n",
    "                venue = venue + ', ' + b['publisher']\n",
    "\n",
    "        citation += \" <b>\" + html_escape(venue)\n",
    "        if 'volume' in b.keys():\n",
    "            citation += ' ' + html_escape(b['volume'])\n",
    "        citation += '</b>'\n",
    "        if 'pages' in b.keys():\n",
    "            citation += ': ' + html_escape(b['pages'])\n",
    "        citation += '.'\n",
    "\n",
    "        \n",
    "        ## YAML variables\n",
    "        md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "        \n",
    "        md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "        #md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "        \n",
    "        note = False\n",
    "        if \"note\" in b.keys():\n",
    "            if len(str(b[\"note\"])) > 5:\n",
    "                md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                note = True\n",
    "\n",
    "        md += \"\\ndate: \" + str(pub_date) \n",
    "        md += \"\\nyear: \" + pub_year\n",
    "\n",
    "        md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "        \n",
    "        paper_url = ''\n",
    "        url = False\n",
    "        if \"url\" in b.keys():\n",
    "            if len(str(b[\"url\"])) > 5:\n",
    "                paper_url = str(b[\"url\"])\n",
    "                url       = True\n",
    "        \n",
    "        if not url:\n",
    "            if \"doi\" in b.keys():\n",
    "                if len(str(b[\"doi\"])) > 5:\n",
    "                    paper_url = \"https://dx.doi.org/\" + str(b[\"doi\"])\n",
    "                    url       = True\n",
    "                \n",
    "        if url and (len(paper_url)>0):\n",
    "            md += \"\\npaperurl: '\" + paper_url + \"'\"\n",
    "\n",
    "        md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "        md += \"\\npubtype:  \" + pub_type\n",
    "\n",
    "        md += \"\\n---\"\n",
    "\n",
    "        \n",
    "        ## Markdown description for individual page\n",
    "        if note:\n",
    "            md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "        \n",
    "        if \"abstract\" in b.keys():\n",
    "            md += '\\n' + b['abstract']\n",
    "\n",
    "        #obj_type = 'paper'\n",
    "        #if bibdata.entries[bib_id].type.lower() in ['book','incollection','inproceedings']:\n",
    "        #    obj_type = 'book'\n",
    "        #elif 'thesis' in bibdata.entries[bib_id].type.lower():\n",
    "        #    obj_type = 'dissertation'\n",
    "        #if url:\n",
    "        #    md += \"\\n[Access \" + obj_type + \" here](\" + paper_url + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "        #else:\n",
    "        #    md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "        md_filename = os.path.basename(md_filename)\n",
    "        with open(\"../_publications/\" + md_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(md)\n",
    "        print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "    # field may not exist for a reference\n",
    "    except KeyError as e:\n",
    "        print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
