{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Talks markdown generator for academicpages\n",
    "\n",
    "This file takes the talks from my latex CV in Overleaf and in 'D:/Dropbox/p/documentos/curriculum_vitae/template03_overleaf_em_uso/cv_en-US.tex'\n",
    "and converts to the markdown style needed for the academics page \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "filename = 'D:/Dropbox/p/documentos/curriculum_vitae/template03_overleaf_em_uso/cv_en-US.tex'\n",
    "f = open(filename,'r',encoding='utf-8')\n",
    "d = f.readlines()\n",
    "f.close()\n",
    "\n",
    "def find_first_line(text,line_list,start_line=0,case_sensitive=True):\n",
    "    if case_sensitive:\n",
    "        compare_func = lambda txt,line: txt in line\n",
    "    else:\n",
    "        compare_func = lambda txt,line: txt.lower() in line.lower()\n",
    "    for k,l in enumerate(line_list[start_line:]):\n",
    "        if compare_func(text,l):\n",
    "            return start_line + k\n",
    "    return -1\n",
    "\n",
    "def get_closing_line(node_type,line_list,start_line=0):\n",
    "    node_type = node_type.lower()\n",
    "    all_node_types = [ 'part','chapter','section','subsection','subsubsection' ]\n",
    "    assert node_type in all_node_types, 'Invalid node_type'\n",
    "    k = 1 + all_node_types.index(node_type)\n",
    "    correct_value = lambda v: v if v > -1 else float('inf')\n",
    "    return int(min([ correct_value(find_first_line('\\\\' + n,line_list,start_line=start_line+1,case_sensitive=False)) for n in all_node_types[:k] ]))\n",
    "\n",
    "def get_start_line(node_type,line_list,title=''):\n",
    "    all_node_types = [ 'part','chapter','section','subsection','subsubsection' ]\n",
    "    assert node_type in all_node_types, 'Invalid node_type'\n",
    "    found      = False\n",
    "    start_line = -1\n",
    "    while not found:\n",
    "        start_line = find_first_line('\\\\' + node_type,line_list,start_line=start_line+1,case_sensitive=False)\n",
    "        if start_line == -1:\n",
    "            return -1\n",
    "        if len(title) > 0:\n",
    "            if title in line_list[start_line]:\n",
    "                return start_line\n",
    "        else:\n",
    "            return start_line\n",
    "    return -1\n",
    "\n",
    "def get_section(title,line_list):\n",
    "    start_line = get_start_line('section',line_list,title=title)\n",
    "    if start_line == -1:\n",
    "        return []\n",
    "    end_line = get_closing_line('section',line_list,start_line=start_line)\n",
    "    return line_list[start_line:end_line]\n",
    "\n",
    "def get_subsection(title,line_list):\n",
    "    start_line = get_start_line('subsection',line_list,title=title)\n",
    "    if start_line == -1:\n",
    "        return []\n",
    "    end_line = get_closing_line('subsection',line_list,start_line=start_line)\n",
    "    return line_list[start_line:end_line]\n",
    "\n",
    "\n",
    "def get_all_node_lines(node_name,line_list):\n",
    "    nl = []\n",
    "    for l in line_list:\n",
    "        if f'\\\\{node_name}'.lower() in l.lower():\n",
    "            nl.append(l)\n",
    "    return nl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    if type(text) is str:\n",
    "        return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "    else:\n",
    "        return \"False\"\n",
    "\n",
    "def clean_bibstring(text):\n",
    "    escapes    = ''.join([chr(char) for char in range(1, 32)])\n",
    "    translator = str.maketrans('', '', escapes)\n",
    "    return text.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").translate(translator)\n",
    "\n",
    "def get_latex_url(text):\n",
    "    try:\n",
    "        r = text.split(r'\\url{')[1].split('}')[0]\n",
    "    except IndexError:\n",
    "        r = ''\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cventries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6723217ed1d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m \u001b[0mclean_bibstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcventries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_bibstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cventries' is not defined"
     ]
    }
   ],
   "source": [
    "[ clean_bibstring(s) for s in cventries[0].split('{') if len(clean_bibstring(s)) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cventries = get_all_node_lines('cventry', get_subsection('Conference Presentations',d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\cventry{2020}{Neuroscience and Memory Mechanisms}{}{Online interview for the University of the Extreme South of Santa Catarina}{Brazil}{}{}\\n',\n",
       " '\\\\cventry{2020}{Modeling in Science beyond the COVID-19 Pandemic}{}{Online interview for the Federal Institute of Santa Catarina for Science, Technology and Education}{Brazil}{}{}\\n',\n",
       " '\\\\cventry{2014--2016}{Open astronomical observations of the Lunar eclipses and the transit of Mercury}{Organizer/Speaker}{}{Florianopolis, Brazil}{}{}\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cventries = get_all_node_lines('cventry', get_subsection('Outreach',d))\n",
    "cventries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "is_single_year = lambda s: (len(s) <= 4) and (not ('-' in s))\n",
    "\n",
    "\n",
    "cventries = get_all_node_lines('cventry', get_subsection('Outreach',d))\n",
    "\n",
    "loc_dict = {}\n",
    "\n",
    "talk_month = \"01\"\n",
    "talk_day = \"01\"\n",
    "\n",
    "talk_type = 'Community outreach and interviews'\n",
    "\n",
    "for row, cventry in enumerate(cventries):\n",
    "\n",
    "    item = [ clean_bibstring(s) for s in cventry.split('{')[1:] if len(clean_bibstring(s)) > 0 ]\n",
    "    # item 0 -> year (or year range)\n",
    "    # item 1 -> title\n",
    "    # remaining -> venue\n",
    "    talk_year  = item[0].replace('--',' to ')\n",
    "    talk_title = item[1].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "    talk_venue = ', '.join(item[2:])\n",
    "    talk_url   = get_latex_url(cventry)\n",
    "\n",
    "    clean_title = talk_title.replace(\" \",\"-\")\n",
    "    url_slug    = re.sub(\"[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "    url_slug    = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "    talk_date = item[0]\n",
    "\n",
    "    md_filename   = (str(talk_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "    html_filename = (str(talk_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"      + talk_title + '\"\\n'\n",
    "    md += \"collection: talks\"  + \"\\n\"\n",
    "    md += 'type: \"'            + talk_type + '\"\\n'\n",
    "    md += \"permalink: /talks/\" + html_filename + \"\\n\"\n",
    "    md += 'venue: \"'           + talk_venue + '\"\\n'\n",
    "    md += \"year: \"             + talk_year + \"\\n\"\n",
    "    md += \"---\\n\"\n",
    "    \n",
    "    \n",
    "    if len(talk_url) > 3:\n",
    "        md += \"\\n[See more here](\" + talk_url + \")\\n\" \n",
    "        \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    #print(md)\n",
    "    \n",
    "    with open(\"../_talks/\" + md_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the talks directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury.md\n",
      "2020-Modeling-in-Science-beyond-the-COVID-19-Pandemic.md\n",
      "2020-Neuroscience-and-Memory-Mechanisms.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Open astronomical observations of the Lunar eclipses and the transit of Mercury\"\n",
      "collection: talks\n",
      "type: \"Community outreach and interviews\"\n",
      "permalink: /talks/2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury\n",
      "venue: \"Organizer/Speaker, Florianopolis, Brazil\"\n",
      "date: 2014 to 2016\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "!cat ../_talks/2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
