{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Talks markdown generator for academicpages\n",
    "\n",
    "This file takes the talks from my latex CV in Overleaf and in 'D:/Dropbox/p/documentos/curriculum_vitae/template03_overleaf_em_uso/cv_en-US.tex'\n",
    "and converts to the markdown style needed for the academics page \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "filename = 'D:/Dropbox/p/documentos/curriculum_vitae/template03_overleaf_em_uso/cv_en-US.tex'\n",
    "f = open(filename,'r',encoding='utf-8')\n",
    "d = f.readlines()\n",
    "f.close()\n",
    "\n",
    "def find_first_line(text,line_list,start_line=0,case_sensitive=True):\n",
    "    if case_sensitive:\n",
    "        compare_func = lambda txt,line: txt in line\n",
    "    else:\n",
    "        compare_func = lambda txt,line: txt.lower() in line.lower()\n",
    "    for k,l in enumerate(line_list[start_line:]):\n",
    "        if compare_func(text,l):\n",
    "            return start_line + k\n",
    "    return -1\n",
    "\n",
    "def get_closing_line(node_type,line_list,start_line=0):\n",
    "    node_type = node_type.lower()\n",
    "    all_node_types = [ 'part','chapter','section','subsection','subsubsection' ]\n",
    "    assert node_type in all_node_types, 'Invalid node_type'\n",
    "    k = 1 + all_node_types.index(node_type)\n",
    "    correct_value = lambda v: v if v > -1 else float('inf')\n",
    "    return int(min([ correct_value(find_first_line('\\\\' + n,line_list,start_line=start_line+1,case_sensitive=False)) for n in all_node_types[:k] ]))\n",
    "\n",
    "def get_start_line(node_type,line_list,title=''):\n",
    "    all_node_types = [ 'part','chapter','section','subsection','subsubsection' ]\n",
    "    assert node_type in all_node_types, 'Invalid node_type'\n",
    "    found      = False\n",
    "    start_line = -1\n",
    "    while not found:\n",
    "        start_line = find_first_line('\\\\' + node_type,line_list,start_line=start_line+1,case_sensitive=False)\n",
    "        if start_line == -1:\n",
    "            return -1\n",
    "        if len(title) > 0:\n",
    "            if title in line_list[start_line]:\n",
    "                return start_line\n",
    "        else:\n",
    "            return start_line\n",
    "    return -1\n",
    "\n",
    "def get_section(title,line_list):\n",
    "    start_line = get_start_line('section',line_list,title=title)\n",
    "    if start_line == -1:\n",
    "        return []\n",
    "    end_line = get_closing_line('section',line_list,start_line=start_line)\n",
    "    return line_list[start_line:end_line]\n",
    "\n",
    "def get_subsection(title,line_list):\n",
    "    start_line = get_start_line('subsection',line_list,title=title)\n",
    "    if start_line == -1:\n",
    "        return []\n",
    "    end_line = get_closing_line('subsection',line_list,start_line=start_line)\n",
    "    return line_list[start_line:end_line]\n",
    "\n",
    "\n",
    "def get_all_node_lines(node_name,line_list):\n",
    "    nl = []\n",
    "    for l in line_list:\n",
    "        if f'\\\\{node_name}'.lower() in l.lower():\n",
    "            nl.append(l)\n",
    "    return nl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    if type(text) is str:\n",
    "        return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "    else:\n",
    "        return \"False\"\n",
    "\n",
    "def clean_bibstring(text):\n",
    "    escapes    = ''.join([chr(char) for char in range(1, 32)])\n",
    "    translator = str.maketrans('', '', escapes)\n",
    "    return text.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").translate(translator)\n",
    "\n",
    "def get_latex_url(text):\n",
    "    try:\n",
    "        r = text.split(r'\\url{')[1].split('}')[0]\n",
    "    except IndexError:\n",
    "        r = ''\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_for_page = 'talks'\n",
    "\n",
    "# process talks\n",
    "all_files        = glob.glob('./_talks/*.md')\n",
    "outfilename      = '_includes/toc-talks'\n",
    "pubtype_tag      = 'type'\n",
    "year_tag         = 'year'\n",
    "year_dtype       = int\n",
    "pubtype_order    = ['outreach','invited','conference']\n",
    "pubtype_link_txt = dict(outreach='Interviews and Science Outreach',invited='Invited Talks',conference='Latest Conference Presentations')\n",
    "\n",
    "\n",
    "finfo = []\n",
    "for file in all_files:\n",
    "    print(file)\n",
    "    finfo.append(get_file_header_info(file))\n",
    "\n",
    "type_unique_values = get_unique_values_for_tag(finfo,pubtype_tag)\n",
    "type_unique_values = [ type_unique_values[[ k in v.lower() for v in type_unique_values ]][0] for k in pubtype_order ]\n",
    "type_map           = { k:v for k,v in zip(pubtype_link_txt.keys(),type_unique_values) }\n",
    "type_map_reverse   = { v:k for k,v in type_map.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\cventry{2024}{Three body problem: science beyind Netflix}{Pint of Science Florianopolis}{}{Brazil}{}{}\\n',\n",
       " '\\\\cventry{2020}{Neuroscience and Memory Mechanisms}{}{Online interview for the University of the Extreme South of Santa Catarina}{Brazil. See more in \\\\url{https://bit.ly/entrevistas-palestras}}{}{}\\n',\n",
       " '\\\\cventry{2020}{Modeling in Science beyond the COVID-19 Pandemic}{}{Online interview for the Federal Institute of Santa Catarina for Science, Technology and Education}{Brazil. See more in \\\\url{https://bit.ly/entrevistas-palestras}}{}{}\\n',\n",
       " '\\\\cventry{2019}{Can a butterfly flap its wings in China and cause a tornado in Brazil?}{Pint of Science Florianopolis}{}{Brazil}{}{}\\n',\n",
       " '\\\\cventry{2014}{Open astronomical observations and modern physics communication to the public}{Organizer (ongoing project)}{}{Florianopolis, Brazil. See more in \\\\url{https://bit.ly/extensaoIFSC}}{}{}\\n']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cventries = get_all_node_lines('cventry', get_subsection('Outreach',d))\n",
    "cventries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "is_single_year = lambda s: (len(s) <= 4) and (not ('-' in s))\n",
    "\n",
    "cventries = get_all_node_lines('cventry', get_subsection('Outreach',d))\n",
    "\n",
    "loc_dict = {}\n",
    "\n",
    "talk_month = \"01\"\n",
    "talk_day   = \"01\"\n",
    "\n",
    "talk_type       = 'Community outreach and interviews'\n",
    "talk_collection = 'talks'\n",
    "talk_dir        = '../_talks'\n",
    "os.makedirs(talk_dir,exist_ok=True)\n",
    "result = [ os.remove(os.path.join(talk_dir,f)) for f in os.listdir(talk_dir) ]\n",
    "\n",
    "for row, cventry in enumerate(cventries):\n",
    "\n",
    "    item = [ clean_bibstring(s) for s in cventry.split('{')[1:] if len(clean_bibstring(s)) > 0 ]\n",
    "    # item 0 -> year (or year range)\n",
    "    # item 1 -> title\n",
    "    # remaining -> venue\n",
    "    talk_year  = item[0].replace('--',' to ')\n",
    "    talk_title = item[1].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "    talk_venue = ', '.join(item[2:])\n",
    "    talk_url   = get_latex_url(cventry)\n",
    "\n",
    "    clean_title = talk_title.replace(\" \",\"-\")\n",
    "    url_slug    = re.sub(\"[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "    url_slug    = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "    talk_date = item[0]\n",
    "\n",
    "    md_filename   = (str(talk_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "    html_filename = (str(talk_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"      + talk_title      + '\"\\n'\n",
    "    md += \"collection: \"       + talk_collection + \"\\n\"\n",
    "    md += 'type: \"'            + talk_type       + '\"\\n'\n",
    "    #md += \"permalink: /talks/\" + html_filename   + \"\\n\"\n",
    "    md += 'venue: \"'           + talk_venue      + '\"\\n'\n",
    "    md += \"year: \"             + talk_year       + \"\\n\"\n",
    "    md += \"---\\n\"\n",
    "    \n",
    "    \n",
    "    if len(talk_url) > 3:\n",
    "        md += \"\\n[See more here](\" + talk_url + \")\\n\" \n",
    "        \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    #print(md)\n",
    "    \n",
    "    with open(os.path.join(talk_dir,md_filename), 'w', encoding='utf-8') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury.md\n",
      "2019-Can-a-butterfly-flap-its-wings-in-China-and-cause-a-tornado-in-Brazil.md\n",
      "2020-Modeling-in-Science-beyond-the-COVID-19-Pandemic.md\n",
      "2020-Neuroscience-and-Memory-Mechanisms.md\n",
      "2024-Three-body-problem-science-beyind-Netflix.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_single_year = lambda s: (len(s) <= 4) and (not ('-' in s))\n",
    "\n",
    "cventries = get_all_node_lines('cventry', get_subsection('Invited Talks',d))\n",
    "\n",
    "loc_dict = {}\n",
    "\n",
    "talk_month = \"01\"\n",
    "talk_day   = \"01\"\n",
    "\n",
    "talk_type       = 'Invited talks'\n",
    "talk_collection = 'talks'\n",
    "talk_dir        = '../_talks'\n",
    "#os.makedirs(talk_dir,exist_ok=True)\n",
    "#result = [ os.remove(os.path.join(talk_dir,f)) for f in os.listdir(talk_dir) ]\n",
    "\n",
    "for row, cventry in enumerate(cventries):\n",
    "\n",
    "    item = [ clean_bibstring(s) for s in cventry.split('{')[1:] if len(clean_bibstring(s)) > 0 ]\n",
    "    # item 0 -> year (or year range)\n",
    "    # item 1 -> title\n",
    "    # remaining -> venue\n",
    "    talk_year  = item[0].replace('--',' to ')\n",
    "    talk_title = item[1].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "    talk_venue = ', '.join(item[2:])\n",
    "    talk_url   = get_latex_url(cventry)\n",
    "\n",
    "    clean_title = talk_title.replace(\" \",\"-\")\n",
    "    url_slug    = re.sub(\"[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "    url_slug    = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "    talk_date = item[0]\n",
    "\n",
    "    md_filename   = (str(talk_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "    html_filename = (str(talk_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"      + talk_title      + '\"\\n'\n",
    "    md += \"collection: \"       + talk_collection + \"\\n\"\n",
    "    md += 'type: \"'            + talk_type       + '\"\\n'\n",
    "    #md += \"permalink: /talks/\" + html_filename   + \"\\n\"\n",
    "    md += 'venue: \"'           + talk_venue      + '\"\\n'\n",
    "    md += \"year: \"             + talk_year       + \"\\n\"\n",
    "    md += \"---\\n\"\n",
    "    \n",
    "    \n",
    "    if len(talk_url) > 3:\n",
    "        md += \"\\n[See more here](\" + talk_url + \")\\n\" \n",
    "        \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    #print(md)\n",
    "    \n",
    "    with open(os.path.join(talk_dir,md_filename), 'w', encoding='utf-8') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury.md\n",
      "2018-The-chemistry-that-makes-us-think-and-feel-how-ions-and-molecules-control-our-behavior.md\n",
      "2019-Can-a-butterfly-flap-its-wings-in-China-and-cause-a-tornado-in-Brazil.md\n",
      "2020-A-self-organized-path-to-synaptic-balance.md\n",
      "2020-Modeling-in-Science-beyond-the-COVID-19-Pandemic.md\n",
      "2020-Neuroscience-and-Memory-Mechanisms.md\n",
      "2021-Neuronal-avalanches-are-they-generally-representative-of-critical-brain-dynamics.md\n",
      "2024-Three-body-problem-science-beyind-Netflix.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_single_year = lambda s: (len(s) <= 4) and (not ('-' in s))\n",
    "\n",
    "cventries = get_all_node_lines('cventry', get_subsection('Conference Presentations',d))\n",
    "\n",
    "loc_dict = {}\n",
    "\n",
    "talk_month = \"01\"\n",
    "talk_day   = \"01\"\n",
    "\n",
    "talk_type       = 'Conference presentations'\n",
    "talk_collection = 'talks'\n",
    "talk_dir        = '../_talks'\n",
    "#os.makedirs(talk_dir,exist_ok=True)\n",
    "#result = [ os.remove(os.path.join(talk_dir,f)) for f in os.listdir(talk_dir) ]\n",
    "\n",
    "for row, cventry in enumerate(cventries):\n",
    "\n",
    "    item = [ clean_bibstring(s) for s in cventry.split('{')[1:] if len(clean_bibstring(s)) > 0 ]\n",
    "    # item 0 -> year (or year range)\n",
    "    # item 1 -> title\n",
    "    # remaining -> venue\n",
    "    talk_year  = item[0].replace('--',' to ')\n",
    "    talk_title = item[1].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "    talk_venue = ', '.join(item[2:])\n",
    "    talk_url   = get_latex_url(cventry)\n",
    "\n",
    "    clean_title = talk_title.replace(\" \",\"-\")\n",
    "    url_slug    = re.sub(\"[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "    url_slug    = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "    talk_date = item[0]\n",
    "\n",
    "    md_filename   = (str(talk_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "    html_filename = (str(talk_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"      + talk_title      + '\"\\n'\n",
    "    md += \"collection: \"       + talk_collection + \"\\n\"\n",
    "    md += 'type: \"'            + talk_type       + '\"\\n'\n",
    "    #md += \"permalink: /talks/\" + html_filename   + \"\\n\"\n",
    "    md += 'venue: \"'           + talk_venue      + '\"\\n'\n",
    "    md += \"year: \"             + talk_year       + \"\\n\"\n",
    "    md += \"---\\n\"\n",
    "    \n",
    "    \n",
    "    if len(talk_url) > 3:\n",
    "        md += \"\\n[See more here](\" + talk_url + \")\\n\" \n",
    "        \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    #print(md)\n",
    "    \n",
    "    with open(os.path.join(talk_dir,md_filename), 'w', encoding='utf-8') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the talks directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury.md\n",
      "2018-A-stochastic-and-population-model-of-epileptic-seizures.md\n",
      "2018-Map-based-neurons-a-general-model-for-the-action-potential.md\n",
      "2018-The-chemistry-that-makes-us-think-and-feel-how-ions-and-molecules-control-our-behavior.md\n",
      "2019-A-map-based-model-for-the-membrane-potential-of-healthy-and-unhealthy-neurons-and-cardiac-cells.md\n",
      "2019-Can-a-butterfly-flap-its-wings-in-China-and-cause-a-tornado-in-Brazil.md\n",
      "2019-How-to-self-organize-a-neuronal-network-towards-the-balanced-state.md\n",
      "2019-Power-law-avalanches-and-all-the-synchronicity-states-emerging-in-a-unified-model-of-excitatory-inhibitory-balanced-network.md\n",
      "2020-A-self-organized-path-to-synaptic-balance.md\n",
      "2020-Directed-percolation-explains-experimental-avalanche-scaling-laws-under-subsampling.md\n",
      "2020-Modeling-in-Science-beyond-the-COVID-19-Pandemic.md\n",
      "2020-Neuroscience-and-Memory-Mechanisms.md\n",
      "2021-A-minimal-integrate-and-fire-model-for-Mossy-Cells.md\n",
      "2021-Asynchronous-irregular-activity-coexists-with-power-law-distributed-neuronal-avalanches.md\n",
      "2021-Neuronal-avalanches-are-they-generally-representative-of-critical-brain-dynamics.md\n",
      "2022-Brain-criticality-beyond-avalanches-open-problems-and-how-to-approach-them.md\n",
      "2023-Coding-properties-of-networks-with-firing-threshold-adaptation-near-criticality.md\n",
      "2024-Optimal-coding-and-information-processing-due-to-firing-threshold-adaptation-near-criticality.md\n",
      "2024-Optimal-pattern-coding-due-to-firing-threshold-adaptation-near-criticality.md\n",
      "2024-Three-body-problem-science-beyind-Netflix.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Open astronomical observations of the Lunar eclipses and the transit of Mercury\"\n",
      "collection: talks\n",
      "type: \"Community outreach and interviews\"\n",
      "venue: \"Organizer/Speaker, Florianopolis, Brazil. See more in url, https://bit.ly/extensaoIFSC\"\n",
      "year: 2014 to 2016\n",
      "---\n",
      "\n",
      "[See more here](https://bit.ly/extensaoIFSC)\n"
     ]
    }
   ],
   "source": [
    "!cat ../_talks/2014-2016-Open-astronomical-observations-of-the-Lunar-eclipses-and-the-transit-of-Mercury.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
